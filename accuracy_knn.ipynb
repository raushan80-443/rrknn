{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5ed6ef-009d-4e50-8d07-ac2b6abf45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "class GeneralizedSocialDistanceKNN:\n",
    "    def __init__(self, n_neighbors=3, k=2, X=None, y=None, file_name=\"accuracy_result.json\"):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.k = k\n",
    "        self.knn = None\n",
    "        self.file_name = file_name  # File name to save results\n",
    "\n",
    "        # Use passed dataset or default to Iris dataset\n",
    "        if X is None or y is None:\n",
    "            data = load_iris()  # Load the iris dataset\n",
    "            self.X = data.data\n",
    "            self.y = data.target\n",
    "        else:\n",
    "            self.X = X  # Features\n",
    "            self.y = y  # Labels\n",
    "\n",
    "        # Split dataset into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.1, random_state=42)\n",
    "\n",
    "        # Standardize the dataset\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "\n",
    "    # Generalized social distance function\n",
    "    def generalized_social_distance(self, x, y, data_set=None):\n",
    "        def euclidean_distance(p1, p2):\n",
    "            return np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "\n",
    "        distances_x = [euclidean_distance(x, point) for point in data_set]\n",
    "        distances_y = [euclidean_distance(y, point) for point in data_set]\n",
    "\n",
    "        mx_y = sum(1 for dx in distances_x if 0 < dx < euclidean_distance(x, y))\n",
    "        mx_eq = sum(1 for dx in distances_x if dx == euclidean_distance(x, y))\n",
    "        my_x = sum(1 for dy in distances_y if 0 < dy < euclidean_distance(x, y))\n",
    "        my_eq = sum(1 for dy in distances_y if dy == euclidean_distance(x, y))\n",
    "\n",
    "        if mx_y + mx_eq == 0 or my_x + my_eq == 0:\n",
    "            return float('inf')\n",
    "\n",
    "        lk_distance = (mx_y**self.k + mx_eq**self.k) / (mx_y + mx_eq) + (my_x**self.k + my_eq**self.k) / (my_x + my_eq)\n",
    "        generalized_social_distance = lk_distance / (1 + lk_distance)\n",
    "\n",
    "        return generalized_social_distance\n",
    "\n",
    "    # Wrapper for the KNN distance metric\n",
    "    def generalized_social_distance_wrapper(self, x, y):\n",
    "        return self.generalized_social_distance(x, y, data_set=self.X_train)\n",
    "\n",
    "    # Train the KNN model\n",
    "    def train_knn(self):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=self.n_neighbors, metric=self.generalized_social_distance_wrapper,n_jobs=-1)\n",
    "        self.knn.fit(self.X_train, self.y_train)\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    def evaluate(self):\n",
    "        y_pred_knn = self.knn.predict(self.X_test)\n",
    "        knn_accuracy = accuracy_score(self.y_test, y_pred_knn)\n",
    "        return knn_accuracy\n",
    "\n",
    "    # Save accuracy to the specified JSON file\n",
    "    def save_accuracy_to_json(self):\n",
    "        accuracy = self.evaluate()\n",
    "\n",
    "        try:\n",
    "            # Read the existing data in the JSON file\n",
    "            with open(self.file_name, 'r') as file:\n",
    "                results = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            # If file doesn't exist, create an empty dictionary\n",
    "            results = {}\n",
    "\n",
    "        # Add the current accuracy for the specific `n_neighbors` value under the dataset key (using the file name as the key)\n",
    "        dataset_key = self.file_name.split('.')[0]  # Extract dataset name from file name\n",
    "        if dataset_key not in results:\n",
    "            results[dataset_key] = {}\n",
    "\n",
    "        results[dataset_key][str(self.n_neighbors)] = accuracy\n",
    "\n",
    "        # Write the updated results back to the JSON file\n",
    "        with open(self.file_name, 'w') as file:\n",
    "            json.dump(results, file, indent=4)\n",
    "\n",
    "# Usage Example: Run KNN with n_neighbors from 1 to 15 and save accuracies to a custom JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f6d11c-057d-49cd-93f5-9bdb0da12857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "def fetch_and_prepare_data(dataset_id):\n",
    "    # Fetch dataset\n",
    "    dataset = fetch_ucirepo(id=dataset_id)\n",
    "    \n",
    "    # Extract features and targets\n",
    "    X = dataset.data.features\n",
    "    y = dataset.data.targets.squeeze()\n",
    "    \n",
    "    # Ensure X is a DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "    \n",
    "    # Convert categorical columns to numerical\n",
    "    for column in X.columns:\n",
    "        if X[column].dtype == 'object':\n",
    "            X = pd.get_dummies(X, columns=[column], drop_first=True)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8670d6dd-afeb-4413-ab99-54a1e44c3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(n_neighbors, X, y, file_name):\n",
    "    print(f\"Running KNN with n_neighbors={n_neighbors}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=n_neighbors, X=X, y=y, file_name=file_name)\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ace8e17-112d-42b4-8d04-c0af2de8a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def parallel_knn(dataset_id, file_name, n_jobs=-1):\n",
    "    # Fetch and prepare data\n",
    "    X, y = fetch_and_prepare_data(dataset_id)\n",
    "    \n",
    "    # Run KNN in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(run_knn)(k, X, y, file_name) for k in range(1, 16)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce07d18-ec81-4910-970b-735cad9c1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parallel_knn(dataset_id=176, file_name=\"blood_transfusion.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "602157de-2f08-4c46-a209-714f8aad8eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN with n_neighbors=1\n",
      "Running KNN with n_neighbors=2\n",
      "Running KNN with n_neighbors=3\n",
      "Running KNN with n_neighbors=4\n",
      "Running KNN with n_neighbors=5\n",
      "Running KNN with n_neighbors=6\n",
      "Running KNN with n_neighbors=7\n",
      "Running KNN with n_neighbors=8\n",
      "Running KNN with n_neighbors=9\n",
      "Running KNN with n_neighbors=10\n",
      "Running KNN with n_neighbors=11\n",
      "Running KNN with n_neighbors=12\n",
      "Running KNN with n_neighbors=13\n",
      "Running KNN with n_neighbors=14\n",
      "Running KNN with n_neighbors=15\n",
      "CPU times: user 1min 13s, sys: 970 ms, total: 1min 14s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for k in range(1, 16):\n",
    "    print(f\"Running KNN with n_neighbors={k}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=k, file_name=\"iris.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030ee725-b154-411a-92f8-31074897d187",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"<timed exec>\", line 14, in run_knn\n  File \"/tmp/ipykernel_57954/2426073093.py\", line 76, in save_accuracy_to_json\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/home/raushan80_443/miniconda3/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:18\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "\n",
    "# Assuming GeneralizedSocialDistanceKNN is defined elsewhere\n",
    "\n",
    "# Time the execution of the KNN models\n",
    "\n",
    "\n",
    "# Function to train the model and save accuracy\n",
    "def run_knn(n_neighbors):\n",
    "    print(f\"Running KNN with n_neighbors={n_neighbors}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=n_neighbors, file_name=\"iris.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n",
    " \n",
    "\n",
    "# Use Parallel for parallel processing\n",
    "results = Parallel(n_jobs=-1)(delayed(run_knn)(k) for k in range(1, 16))\n",
    "\n",
    "# # Optionally, save results to a JSON file after the loop\n",
    "# with open(\"knn_results.json\", \"w\") as f:\n",
    "#     json.dump(results, f)\n",
    "\n",
    "        # Optionally, you can append results to a list if you want to keep track of them\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486543b7-2bcd-46ca-9a90-a6699c844dd6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN with n_neighbors=1\n",
      "Running KNN with n_neighbors=2\n",
      "Running KNN with n_neighbors=3\n",
      "Running KNN with n_neighbors=4\n",
      "Running KNN with n_neighbors=5\n",
      "Running KNN with n_neighbors=6\n",
      "Running KNN with n_neighbors=7\n",
      "Running KNN with n_neighbors=8\n",
      "Running KNN with n_neighbors=9\n",
      "Running KNN with n_neighbors=10\n",
      "Running KNN with n_neighbors=11\n",
      "Running KNN with n_neighbors=12\n",
      "Running KNN with n_neighbors=13\n",
      "Running KNN with n_neighbors=14\n",
      "Running KNN with n_neighbors=15\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "ecoli = fetch_ucirepo(id=39) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = ecoli.data.features \n",
    "y = np.squeeze(ecoli.data.targets)\n",
    "\n",
    "for k in range(1, 16):\n",
    "    print(f\"Running KNN with n_neighbors={k}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=k,  X=X, y=y,file_name=\"ecoli.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d9cd40-b5fe-489b-b247-299e82d7ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 ms, sys: 272 ms, total: 516 ms\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Assuming GeneralizedSocialDistanceKNN is defined elsewhere\n",
    "\n",
    "# Fetch dataset\n",
    "ecoli = fetch_ucirepo(id=39)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = ecoli.data.features\n",
    "y = np.squeeze(ecoli.data.targets)\n",
    "\n",
    "\n",
    "\n",
    "# Function to train the model and save accuracy\n",
    "def run_knn(n_neighbors):\n",
    "    print(f\"Running KNN with n_neighbors={n_neighbors}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=n_neighbors, X=X, y=y, file_name=\"ecoli.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n",
    "\n",
    "# Use Parallel for parallel processing\n",
    "results = Parallel(n_jobs=-1)(delayed(run_knn)(k) for k in range(1, 16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abc3a1a2-0b3a-4a76-948e-9820d568d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 240 ms, total: 448 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset\n",
    "breast_cancer = fetch_ucirepo(id=14)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = breast_cancer.data.features\n",
    "y = np.squeeze(breast_cancer.data.targets)\n",
    "\n",
    "# Convert to DataFrame if it's not already one\n",
    "if not isinstance(X, pd.DataFrame):\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "# Print data types to identify any non-numeric columns (optional)\n",
    "# print(X.dtypes)\n",
    "\n",
    "# Convert categorical columns to numerical using one-hot encoding\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':  # Check if the column is categorical\n",
    "        X = pd.get_dummies(X, columns=[column], drop_first=True)\n",
    "\n",
    "# Time the execution of the KNN models\n",
    "\n",
    "\n",
    "# Function to train the model and save accuracy\n",
    "def run_knn(n_neighbors):\n",
    "    print(f\"Running KNN with n_neighbors={n_neighbors}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=n_neighbors, X=X, y=y, file_name=\"breast_cancer.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n",
    "\n",
    "# Use Parallel for parallel processing\n",
    "results = Parallel(n_jobs=-1)(delayed(run_knn)(k) for k in range(1, 16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594aed85-b4a2-420b-b777-3b0e53ae8dbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN with n_neighbors=1\n",
      "Running KNN with n_neighbors=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 71\u001b[0m, in \u001b[0;36mGeneralizedSocialDistanceKNN.save_accuracy_to_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_accuracy_to_json\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m# Read the existing data in the JSON file\u001b[39;00m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "Cell \u001b[0;32mIn[16], line 65\u001b[0m, in \u001b[0;36mGeneralizedSocialDistanceKNN.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 65\u001b[0m     y_pred_knn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     knn_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, y_pred_knn)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m knn_accuracy\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:903\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    900\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    902\u001b[0m         )\n\u001b[0;32m--> 903\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_tree_query_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "blood_transfusion_service_center = fetch_ucirepo(id=176) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = blood_transfusion_service_center.data.features \n",
    "y = np.squeeze(blood_transfusion_service_center.data.targets)\n",
    "\n",
    "\n",
    "for k in range(1, 16):\n",
    "    print(f\"Running KNN with n_neighbors={k}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=k,  X=X, y=y,file_name=\"blood_transfusion.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093379a-70af-4cdb-8e26-ebd9ccf6d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN with n_neighbors=7\n",
      "Running KNN with n_neighbors=6\n",
      "Running KNN with n_neighbors=10\n",
      "Running KNN with n_neighbors=11\n",
      "Running KNN with n_neighbors=8\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset\n",
    "blood_transfusion_service_center = fetch_ucirepo(id=176)\n",
    "\n",
    "# Data (as pandas dataframes)\n",
    "X = blood_transfusion_service_center.data.features\n",
    "y = np.squeeze(blood_transfusion_service_center.data.targets)\n",
    "\n",
    "# Convert to DataFrame if it's not already one\n",
    "if not isinstance(X, pd.DataFrame):\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "# Convert categorical columns to numerical using one-hot encoding\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':  # Check if the column is categorical\n",
    "        X = pd.get_dummies(X, columns=[column], drop_first=True)\n",
    "\n",
    "# Function to train the model and save accuracy\n",
    "def run_knn(n_neighbors):\n",
    "    print(f\"Running KNN with n_neighbors={n_neighbors}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=n_neighbors, X=X, y=y, file_name=\"blood_transfusion.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()\n",
    "\n",
    "# Use Parallel for parallel processing\n",
    "results = Parallel(n_jobs=-1)(delayed(run_knn)(k) for k in range(1, 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1853b-766a-4c80-a232-5d30f6ad8932",
   "metadata": {},
   "source": [
    "Mixed data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6275c-dabb-4df6-a5ca-4787950d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "acute_inflammations = fetch_ucirepo(id=184) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = acute_inflammations.data.features \n",
    "y = acute_inflammations.data.targets \n",
    "  \n",
    "\n",
    "for k in range(1, 16):\n",
    "    print(f\"Running KNN with n_neighbors={k}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=k,  X=X, y=y,file_name=\"acute_inflammation.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd959f6-c331-42b0-a9aa-e60ae553f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "contraceptive_method_choice = fetch_ucirepo(id=30) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = contraceptive_method_choice.data.features \n",
    "y = contraceptive_method_choice.data.targets \n",
    "\n",
    "\n",
    "\n",
    "for k in range(1, 16):\n",
    "    print(f\"Running KNN with n_neighbors={k}\")\n",
    "    model = GeneralizedSocialDistanceKNN(n_neighbors=k,  X=X, y=y,file_name=\"contraceptive_method_choice.json\")\n",
    "    model.train_knn()\n",
    "    model.save_accuracy_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebff90f-adde-4465-a4bb-2bd4c68cfa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "liver_disorders = fetch_ucirepo(id=60) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = liver_disorders.data.features \n",
    "y = liver_disorders.data.targets \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
